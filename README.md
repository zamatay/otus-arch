# otus-arch

### Для запуска проекта необходимо установить утилиту goose go install github.com/pressly/goose/v3/cmd/goose@latest

### Далее выполнить команду make run, что создаст БД и запустить все компоненты

### Для применения миграций выполнить команду run up

## ДЗ2

## SQL Скрипты
### Создание индекса
CREATE INDEX idx_first_last_name
ON public.users USING btree (first_name, last_name)
include (id, login, birthday, gender_id, city, enabled, interests);

### Анализирование запроса
explain analyse
select id, login, first_name, last_name, birthday, gender_id, city, enabled, interests
from users
where first_name like 'xxxxx%'  and last_name like 'xxxxx%'  
limit 100;

### Порядок нагрузки. 
В течении 10 секунд набирал указанное количество потоков и далее 1 минуту, производилась 
нагрузка с рандомным запросом из 5 символов

### Результаты
|                      |  Sample  |   Average |    Median |    90%   |     95%    |    99%  |  throughput  |
|----------------------|----------|-----------|-----------|----------|------------|---------|--------------|
| 1000 без индекса     |   2236   |  35514    |  45124    |  48452   |   48649    |   48787 |  20,6/sec    |
| 1000 с индексом      |   60360  |  929      |  844      |  2037    |   2339     |   4212  |  982,4/sec   |
| 100 без индекса      |   1287   |  4475     |  4932     |  5356    |   5423     |   5564  |  19,8/sec    |
| 100 с индексом       |   47562  |  76       |  18       |  208     |   238      |   309   |  1144/sec    |
| 10 без индекса       |   1209   |  460      |  415      |  797     |   854      |   974   |  20,1/sec    |
| 10 с индексом        |   56610  |  9        |  11       |  20      |   23       |   28    |  943/sec     |

## ДЗ3

### Порядок нагрузки.
В течении 10 секунд набирал указанное количество потоков и далее 1 минуту, производилась
нагрузка с рандомным запросом из 5 символов по методу Search b рандомному числу по методу Get
В кодовой базе была реализован патерн CQRS с рандомной балансировкой между репликами, после 
чего было повторно сняты показания

### Результаты
|                   | Sample | Average | Median | 90%    | 95%    | 99%    | throughput |
|-------------------|--------|---------|--------|--------|--------|--------|------------|
| 1000 без партиции | 16     | 136488  | 129326 | 153386 | 153393 | 155548 | 6,0/min    |
| 1000 с партицией  | 4057   | 11376   | 11848  | 14135  | 14760  | 15472  | 56,5/sec   |
| 100 без партиции  | 372    | 12971   | 12994  | 17358  | 18265  | 20139  | 5,0/sec    |
| 100 с партицией   | 5034   | 1082    | 1046   | 2002   | 2222   | 2566   | 82,4/sec   |
| 10 без партиции   | 444    | 1232    | 828    | 3795   | 4110   | 4478   | 7,3/sec    |
| 10 с партицией    | 5076   | 109     | 51     | 275    | 414    | 555    | 84,5/sec   |

## ДЗ4

### Лента постов от друзей.

#### Цель:
В результате выполнения ДЗ вы создадите ленту постов друзей социальной сети

В данном задании тренируются навыки:

работа с кешами;
работа с очередями;
проектирование масштабируемых архитектур.
1) Реализовать API (синхронный rest)
   - Добавлены методы /friend/add, /friend/delete
   - Добавлены методы /post/create, /post/update, /post/delete, /post/get
   - Добавлены методы /post/feed
2) Реализовать API (синхронный rest)
    - Доработан сервис migration который наполняет таблицу posts данными
3) Реализовать кэширование ленты
    - В сервис добавлена БД redis
    - В сервис добавлен брокер сообщений kafka
    - При поступлении метода /post/create, /post/update, /post/delete, происходит обновление данных в БД redis
    - Данные обновлются через броке kafka для чего поднят еще один сервис consumer который будет читать данные из kafka 
   и отправлять их в БД redis
    - При получении постов, мы сначало проверяем есть ли эти посты в redis если есть отдаем оттуда, если нет забираем из pg и сохраняем в redis


